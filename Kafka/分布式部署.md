1、准备zookeeper环境

由于zookeeper集群已经搭建好了，集群地址：99.48.18.233:2181,99.48.18.235:2181,99.48.18.236:2181

具体搭建见[zookeeper分布式部署](/Zookeeper/分布式部署.md)

2、在master上下载

下载kafka\_2.11-0.10.1.0.tgz，放到/usr/local/src/目录下

```
wget --no-cookie --no-check-certificate --header "Cookie:oraclelicense=accept-securebackup-cookie" \
-P /usr/local/src http://mirrors.tuna.tsinghua.edu.cn/apache/kafka/0.10.1.0/kafka_2.11-0.10.1.0.tgz
```

3、解压

```
cd /usr/local/src
mkdir /usr/local/kafka && tar --strip-components=1 –xzvfkafka_2.11-0.10.1.0.tgz –C /usr/local/kafka
```

4、创建存放消息目录logs

```
cd /usr/local/kafka
mkdir logs
```

5、修改配置

```
vim ./configserver.properties
```

server.properties完整配置：

```
#当前机器在集群中的唯一标识，和zookeeper的myid性质一样
broker.id=1
#是否可以删除topic，默认为false
delete.topic.enable=true
#socket server监听地址，格式为listeners = security_protocol://host_name:port，
#如果要配置多个必须是协议和端口不一致，地址要一致，
#如果没有配置则取java.net.InetAddress.getCanonicalHostName()返回值
listeners=PLAINTEXT://99.48.18.227:9092
#broker广播给生产者和消费者的地址，如果不配置是取listeners配置，
#如果listeners也没有配置则取java.net.InetAddress.getCanonicalHostName()返回值
advertised.listeners=PLAINTEXT://99.48.18.227:9092
#这个是borker进行网络处理的线程数
num.network.threads=3
#这个是borker进行I/O处理的线程数
num.io.threads=8 
#消息存放的目录，这个目录可以配置为“，”逗号分割的表达式，
#上面的num.io.threads要大于这个目录的个数这个目录，
#如果配置多个目录，新创建的topic他把消息持久化的地方是，当前以逗号分割的目录中，那个分区数最少就放那一个
log.dirs=/usr/local/kafka/logs/
#发送缓冲区buffer大小，数据不是一下子就发送的，先回存储到缓冲区了到达一定的大小后在发送，能提高性能
socket.send.buffer.bytes=102400
#kafka接收缓冲区大小，当数据到达一定大小后在序列化到磁盘
socket.receive.buffer.bytes=102400
#这个参数是向kafka请求消息或者向kafka发送消息的请请求的最大数，这个值不能超过java的堆栈大小
socket.request.max.bytes=104857600
#默认的分区数，一个topic默认1个分区数
num.partitions=1
#默认消息的最大持久化时间，168小时，7天
log.retention.hours=168
#消息保存的最大值5M
message.max.byte=5242880
#kafka保存消息的副本数，如果一个副本失效了，另一个还可以继续提供服务
default.replication.factor=2
#取消息的最大直接数
replica.fetch.max.bytes=5242880
#这个参数是：因为kafka的消息是以追加的形式落地到文件，当超过这个值的时候，kafka会新起一个文件
log.segment.bytes=1073741824
#每隔300000毫秒去检查上面配置的log失效时间（log.retention.hours=168 ），到目录查看是否有过期的消息如果有，删除
log.retention.check.interval.ms=300000
#是否启用log压缩，一般不用启用，启用的话可以提高性能
log.cleaner.enable=false
#设置zookeeper的连接端口
zookeeper.connect=99.48.18.233:2181,99.48.18.235:2181,99.48.18.236:2181
```

实际修改配置项：

```
#每台服务器的broker.id都不能相同
broker.id=1
#socket server监听地址，格式为listeners = security_protocol://host_name:port，
#如果要配置多个必须是协议和端口不一致，地址要一致，
#如果没有配置则取java.net.InetAddress.getCanonicalHostName()返回值
listeners=PLAINTEXT://99.48.18.227:9092
#broker广播给生产者和消费者的地址，如果不配置是取listeners配置，
#如果listeners也没有配置则取java.net.InetAddress.getCanonicalHostName()返回值
advertised.listeners=PLAINTEXT://99.48.18.227:9092

#在log.retention.hours=168下面新增下面三项
message.max.byte=5242880
default.replication.factor=2
replica.fetch.max.bytes=5242880

#设置zookeeper的连接端口
zookeeper.connect=99.48.18.233:2181,99.48.18.235:2181,99.48.18.236:2181
```

6、把配置好的kafka到其他两台机器

```
cd /usr/local
scp -r kafka root@slave01:/usr/local/kafka/
scp -r kafka root@slave02:/usr/local/kafka/
```

修改`server.properties`中的**`broker.id、listeners、advertised.listeners`**

7、启动kafka集群并验证

```
cd /usr/local/kafka
./bin/kafka-server-start.sh -daemon ./config/server.properties
```

验证

```
jps
4501 Kafka
11386 Jps
```

在其他两台机器上也执行，看到afka进程了说明集群搭建成功了

8、topic操作

* 创建topic

```
./bin/kafka-topics.sh --create \
--zookeeper 99.48.18.233:2181,99.48.18.235:2181,99.48.18.236:2181 \
--replication-factor 2 --partitions 1 --topic wechatTest
```

\#解释

--replication-factor 2  \#复制俩份

--partitions 1 \#创建1个分区

--topic wechatTest \#主题为wechatTest

replication-factor大小不能超过broker数

* 查看所有topic

```
./bin/kafka-topics.sh --list --zookeeper 99.48.18.233:2181,99.48.18.235:2181,99.48.18.236:2181
```

![](/assets/kafka-view-all-topic.png)

* 查看topic详情

```
./bin/kafka-topics.sh --describe --zookeeper 99.48.18.233:2181,99.48.18.235:2181,99.48.18.236:2181 --topic wechatTest
```

![](/assets/kafka-topic-details.png)

* 创建生产者

```
./bin/kafka-console-producer.sh --broker-list 99.48.18.227:9092,99.48.18.212:9092,99.48.18.213:9092 --topic wechatTest
```

这个时候终端界面会卡住，不要关闭，输入`hello kafka`

* 在另外一台机器创建消费者

```
./bin/kafka-console-consumer.sh \
--zookeeper 99.48.18.233:2181,99.48.18.235:2181,99.48.18.236:2181 \
--topic wechatTest --from-beginning
```

这个时候可以看到终端输出了hello kafka

9、日志说明

`server.log`

 \#kafka的运行日志

`state-change.log` 

 \#kafka他是用zookeeper来保存状态，所以他可能会进行切换，切换的日志就保存在这里

`controller.log` 

\#kafka选择一个节点作为“controller”,当发现有节点down掉的时候它负责在游泳分区的所有节点中选择新的leader,这使得Kafka可以批量的高效的管理所有分区节点的主从关系。如果controller down掉了，活着的节点中的一个会备切换为新的controller.

10、通过zookeeper查看kafka状态

找一台kafka连接的zookeeper服务器

```
cd /usr/local/zookeeper
./bin/zkCli.sh
```

![](/assets/kafka-status.png)11、Java客户端测试

添加gradle依赖：

```
'org.apache.kafka:kafka-clients:0.10.1.0'
```

创建KafkaUtils，可以创建生产者和消费者

KafkaUtils.java

```
package com.wechat;

import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.producer.KafkaProducer;

import java.util.Properties;

public class KafkaUtils {

    private static KafkaProducer kafkaProducer;

    private static KafkaConsumer kafkaConsumer;

    public static KafkaProducer getProducer() {
        if (kafkaProducer == null) {
            Properties props = new Properties();
            props.put("bootstrap.servers", "99.48.18.227:9092,99.48.18.212:9092,99.48.18.213:9092,");
            props.put("acks", "1");
            props.put("retries", 0);
            props.put("batch.size", 16384);
            props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
            props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");
            kafkaProducer = new KafkaProducer<>(props);
        }
        return kafkaProducer;

    }

    public static KafkaConsumer getConsumer() {
        if (kafkaConsumer == null) {
            Properties props = new Properties();
            props.put("bootstrap.servers", "99.48.18.227:9092,99.48.18.212:9092,99.48.18.213:9092,");
            props.put("group.id", "1");
            props.put("enable.auto.commit", "true");
            props.put("auto.commit.interval.ms", "1000");
            props.put("session.timeout.ms", "30000");
            props.put("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
            props.put("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
            kafkaConsumer = new KafkaConsumer<>(props);
        }
        return kafkaConsumer;
    }

}

```

创建消息生产者KafkaServer

KafkaServer.java

```
package com.wechat;


import org.apache.kafka.clients.producer.Producer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;

public class KafkaServer {

    public static void main(String[] args) throws Exception {
        Producer producer = KafkaUtils.getProducer();
        int i = 0;
        while (i < 10) {
            ProducerRecord record = new ProducerRecord<>("wechatTest", String.valueOf(i), "this is message" + i);
            producer.send(record, (RecordMetadata metadata, Exception e) -> {
                        if (e != null) {
                            e.printStackTrace();
                        }
                        System.out.println("message send to partition " + metadata.partition() + ", offset: " + metadata.offset());
                    }
            );
            i++;
            Thread.sleep(1000);
        }
    }

}
```



