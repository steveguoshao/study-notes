1.在master上下载

下载的是hadoop-2.7.4.tar.gz，与HBase-1.2.6匹配，放到/usr/local/src/目录下

```
wget --no-cookie --no-check-certificate --header "Cookie:oraclelicense=accept-securebackup-cookie" \
    -P /usr/local/src http://mirrors.hust.edu.cn/apache/hadoop/common/hadoop-2.7.4/hadoop-2.7.4.tar.gz
```

2.解压

```
cd /usr/local/src/
mkdir /usr/local/hadoop && tar--strip-components=1 –xzvf hadoop-2.7.4.tar.gz –C /usr/local/hadoop
```

3.修改hadoop配置

hadoop一共7个文件需要修改:

$HADOOP\_HOME/etc/hadoop/hadoop-env.sh

$HADOOP\_HOME/etc/hadoop/yarn-env.sh

$HADOOP\_HOME/etc/hadoop/core-site.xml

$HADOOP\_HOME/etc/hadoop/hdfs-site.xml

$HADOOP\_HOME/etc/hadoop/mapred-site.xml

$HADOOP\_HOME/etc/hadoop/yarn-site.xml

$HADOOP\_HOME/etc/hadoop/slaves

进入hadoop目录 cd /usr/local/hadoop/etc/hadoop目录

1\)    修改hadoop-env.sh和yarn-env.sh, 修改JAVA\_HOME目录，export JAVA\_HOME=/usr/local/java/jdk1.8.0\_144

2\)    core-site.xml

&lt;configuration&gt;

&lt;property&gt;

```
&lt;name&gt;fs.defaultFS&lt;/name&gt;

&lt;value&gt;hdfs://master:9000&lt;/value&gt;
```

&lt;/property&gt;

&lt;property&gt;

```
&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;

&lt;value&gt;/usr/local/hadoop/tmp&lt;/value&gt;
```

&lt;/property&gt;

&lt;/configuration&gt;

core-site.xml的完整参数请参考

[http://hadoop.apache.org/docs/r2.6.2/hadoop-project-dist/hadoop-common/core-default.xml](http://hadoop.apache.org/docs/r2.6.2/hadoop-project-dist/hadoop-common/core-default.xml)

3\)    hdfs-site.xml

&lt;configuration&gt;

&lt;property&gt;

```
&lt;name&gt;dfs.datanode.ipc.address&lt;/name&gt;

&lt;value&gt;0.0.0.0:50020&lt;/value&gt;
```

&lt;/property&gt;

&lt;property&gt;

```
&lt;name&gt;dfs.datanode.http.address&lt;/name&gt;

&lt;value&gt;0.0.0.0:50075&lt;/value&gt;
```

&lt;/property&gt;

&lt;property&gt;

```
&lt;name&gt;dfs.replication&lt;/name&gt;

&lt;value&gt;2&lt;/value&gt;
```

&lt;/property&gt;

&lt;/configuration&gt;

dfs.replication表示数据副本数，一般不大于datanode的节点数。

hdfs-site.xml的完整参数请参考

[http://hadoop.apache.org/docs/r2.6.2/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml](http://hadoop.apache.org/docs/r2.6.2/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml)

4\)    mapred-site.xml

&lt;configuration&gt;

&lt;property&gt;

```
&lt;name&gt;mapreduce.framework.name&lt;/name&gt;

&lt;value&gt;yarn&lt;/value&gt;
```

&lt;/property&gt;

&lt;/configuration&gt;

mapred-site.xml的完整参数请参考

[http://hadoop.apache.org/docs/r2.6.2/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml](http://hadoop.apache.org/docs/r2.6.2/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml)

5\)    yarn-site.xml

&lt;configuration&gt;

&lt;property&gt;

```
&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;

&lt;value&gt;mapreduce\_shuffle&lt;/value&gt;
```

&lt;/property&gt;

&lt;property&gt;

```
    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;

    &lt;value&gt;master&lt;/value&gt;
```

&lt;/property&gt;

&lt;/configuration&gt;

yarn-site.xml的完整参数请参考

[http://hadoop.apache.org/docs/r2.6.2/hadoop-yarn/hadoop-yarn-common/yarn-default.xml](http://hadoop.apache.org/docs/r2.6.2/hadoop-yarn/hadoop-yarn-common/yarn-default.xml)

6\)    slaves

slave01

slave02

1. 初始化namenode

执行./bin/hdfs namenode –format，当看到INFO common.Storage: Storage directory /home/hadoop/tmp/dfs/name has been successfully formatted. 就表示格式化成功

1. 把配置好的hadoop复制到其他机器

scp -r hadoop root@slave01:/usr/local/hadoop/

scp -r hadoop root@slave02:/usr/local/hadoop/

1. 启动整个集群

在master上的/usr/local/Hadoop/目录下执行：

./sbin/start-dfs.sh

jps，如果正常的话, 会有SecondaryNameNode,NameNode两个进程

./sbin/start-yarn.sh

Jps，如果正常的话，就会多一个ResourceManager进程

而slave01的机器上会有DataNode,NodeManager 两个节点

这个时候master上的 50070和 8088 也可以用浏览器访问了: [http://master:50070/](http://master:50070/) [http://master:8088/](http://master:8088/)

